{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "names= set()\n",
    "txt = 'family.txt'\n",
    "with open(txt,'r') as file:\n",
    "    name = file.readlines()\n",
    "for name in name[6:]:\n",
    "    names.add(name.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "txt = 'train.txt'\n",
    "with open(txt, 'r') as file:\n",
    "    data = file.readlines()\n",
    "validation_len = len(data)/5\n",
    "validation_set = data[0:validation_len]\n",
    "train_set = data[validation_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extractShape(word,name):\n",
    "    shape=name\n",
    "    if word[0].isupper():\n",
    "        shape += 'Xx'\n",
    "    if '-' in word:\n",
    "        index = word.index('-')\n",
    "        shape += '-'\n",
    "        if index+1<len(word) and word[index+1].isupper():\n",
    "            shape += 'X'\n",
    "        else: shape += 'x'\n",
    "        if index+2<len(word):\n",
    "            shape += 'x'\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extractSufPre(word,maxlen):\n",
    "    features = []\n",
    "    length = len(word)\n",
    "    maxlen = max(length,maxlen)\n",
    "    for i in range(1,maxlen+1):\n",
    "        features.append(word[:i])\n",
    "        features.append(word[-i:])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extractHypen(word,name):\n",
    "    features = []\n",
    "    if '-' in word:\n",
    "        features.append(name+'hyphen')\n",
    "        index = word.index('-')\n",
    "        features.append(name+word[:index])\n",
    "        features.append(name+word[index:])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def numberGen(word):\n",
    "    result=''\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            result +='D'\n",
    "        else:\n",
    "            result +=char\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def isName(word):\n",
    "    if word in names:\n",
    "        return 'True'\n",
    "    else: return 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract features from words. \n",
    "def word2features(word_line,pos_line,i):\n",
    "    word = word_line[i]\n",
    "    postag = pos_line[i]\n",
    "    features = [\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "        'shape='+extractShape(word,'word'),\n",
    "        'numGen'+numberGen(word),\n",
    "        isName(word)\n",
    "    ]\n",
    "    features.extend(extractSufPre(word,6))\n",
    "    features.extend(extractHypen(word,'word'))\n",
    "    if i > 0:\n",
    "        word1 = word_line[i-1]\n",
    "        postag1 = pos_line[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "            '-1:shape='+extractShape(word1,'-1word'),\n",
    "            'numGen'+numberGen(word1),\n",
    "            '-1:Cap%s'%word1[0].isupper(),\n",
    "            isName(word)\n",
    "\n",
    "        ])\n",
    "        features.extend(extractHypen(word1,'-1word'))\n",
    "\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(word_line)-1:\n",
    "        word1 = word_line[i+1]\n",
    "        postag1 = pos_line[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "            '+1:shape='+extractShape(word1,'+1word'),\n",
    "            'numGen'+numberGen(word1),\n",
    "            '+1:Cap%s' %word1[0].isupper() ,\n",
    "            isName(word)\n",
    "        ])\n",
    "        features.extend(extractHypen(word1,'+1word'))\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# contruct train and test set for trainer\n",
    "def data2features(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(0,len(data),3):\n",
    "        word_line = data[i].split()\n",
    "        pos_line = data[i+1].split()\n",
    "        NE_line = data[i+2].split()\n",
    "\n",
    "        feature = [word2features(word_line,pos_line,i) for i in range(len(word_line))]\n",
    "        label = NE_line\n",
    "\n",
    "        X.append(feature)\n",
    "        Y.append(label)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train = data2features(train_set)\n",
    "X_test,y_test = data2features(validation_set)\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "        digits=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c10.05 c20.05 maxit35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8874    0.9114    0.8993      1332\n",
      "      I-LOC     0.9079    0.8543    0.8803       254\n",
      "     B-MISC     0.9179    0.8798    0.8985       699\n",
      "     I-MISC     0.8543    0.8293    0.8416       205\n",
      "      B-ORG     0.8880    0.8126    0.8486      1297\n",
      "      I-ORG     0.8436    0.7893    0.8155       745\n",
      "      B-PER     0.8645    0.8380    0.8511      1241\n",
      "      I-PER     0.8936    0.9535    0.9226       775\n",
      "\n",
      "avg / total     0.8819    0.8609    0.8707      6548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c1 in [0.05]:\n",
    "    for c2 in [0.05]:\n",
    "        for max_iterations in [35]:\n",
    "            \n",
    "            trainer.set_params({\n",
    "                'c1': c1,   # coefficient for L1 penalty\n",
    "                'c2': c2,  # coefficient for L2 penalty\n",
    "                'max_iterations': max_iterations,  # stop earlier\n",
    "\n",
    "\n",
    "                # include transitions that are possible, but not observed\n",
    "                'feature.possible_transitions': True,\n",
    "\n",
    "            })\n",
    "            trainer.train('NER')\n",
    "            tagger = pycrfsuite.Tagger()\n",
    "            tagger.open('NER')\n",
    "            y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "            print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper function to output the NE results\n",
    "def tagging(begin_index,end_index,tag):\n",
    "    global PER,LOC,ORG,MISC\n",
    "    if tag == 'PER':\n",
    "         PER =  PER+str(begin_index)+'-'+str(end_index)+' '\n",
    "    if tag == 'LOC':\n",
    "        LOC =  LOC+str(begin_index)+'-'+str(end_index)+' '\n",
    "    if tag == 'ORG':\n",
    "        ORG =  ORG+str(begin_index)+'-'+str(end_index)+' '\n",
    "    if tag == 'MISC':\n",
    "        MISC = MISC+str(begin_index)+'-'+str(end_index)+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper function2 to output the NE results\n",
    "def tagging2(tags,num_line):\n",
    "    begin = False\n",
    "    for i in range(len(tags)):\n",
    "        if tags[i][0]=='B':\n",
    "            begin_index = num_line[i]\n",
    "            if begin == True:\n",
    "                tag = tags[i-1][2:]\n",
    "                end_index = num_line[i-1]\n",
    "                tagging(begin_index,end_index,tag)\n",
    "            begin = True\n",
    "            \n",
    "        if tags[i][0]=='O' and begin==True:\n",
    "                tag = tags[i-1][2:]\n",
    "                end_index = num_line[i-1]\n",
    "                tagging(begin_index,end_index,tag)\n",
    "                begin = False\n",
    "                \n",
    "        if i == len(tags) and begin==True:\n",
    "            tag = tags[i][2:]\n",
    "            end_index = num_line[i]\n",
    "            tagging(begin_index,end_index,tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1443e6d50>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'train.txt'\n",
    "with open(txt, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "X_train,y_train = data2features(data)\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "    \n",
    "trainer.set_params({\n",
    "    'c1': 0.05,   # coefficient for L1 penalty\n",
    "    'c2': 0.05,  # coefficient for L2 penalty\n",
    "    'max_iterations': 35,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "trainer.train('NER')\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('NER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "headers = ['Type','Prediction']\n",
    "rows = []\n",
    "PER = ''\n",
    "LOC = ''\n",
    "ORG = ''\n",
    "MISC = ''\n",
    "\n",
    "txt = 'test.txt'\n",
    "with open(txt, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "for i in range(0,len(data),3):\n",
    "        word_line = data[i].split()\n",
    "        pos_line = data[i+1].split()\n",
    "        num_line = data[i+2].split()\n",
    "    \n",
    "        feature = [word2features(word_line,pos_line,i) for i in range(len(word_line))]\n",
    "        tags = tagger.tag(feature)\n",
    "        tagging2(tags,num_line)\n",
    "        \n",
    "\n",
    "\n",
    "rows.append(('PER',PER))\n",
    "rows.append(('LOC',LOC))\n",
    "rows.append(('ORG',ORG))\n",
    "rows.append(('MISC',MISC))\n",
    "               \n",
    "            \n",
    "with open('CRF_2.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def stanfordNE2BIO(tags):\n",
    "    result=[]\n",
    "    prev_tag = \"O\"\n",
    "    for word,tag in tags:\n",
    "        if tag == \"O\": #O\n",
    "            result.append(tag)\n",
    "            prev_tag = tag\n",
    "            continue\n",
    "        if tag != \"O\" and prev_tag == \"O\": # Begin NE\n",
    "            real_tag = tag[0:3]\n",
    "            if real_tag=='MIS':real_tag+='C'\n",
    "            result.append(\"B-\"+real_tag)\n",
    "            prev_tag = tag\n",
    "        elif prev_tag != \"O\" and prev_tag == tag: # Inside NE\n",
    "            real_tag = tag[0:3]\n",
    "            if real_tag=='MIS':real_tag+='C'\n",
    "            result.append(\"I-\"+real_tag)\n",
    "            prev_tag = tag\n",
    "        elif prev_tag != \"O\" and prev_tag != tag: # Adjacent NE\n",
    "            real_tag = tag[0:3]\n",
    "            if real_tag=='MIS':real_tag+='C'\n",
    "            result.append(\"I-\"+real_tag)\n",
    "            prev_tag = tag\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'While', u'O'), (u'in', u'O'), (u'France', u'LOCATION'), (u',', u'O'), (u'Christine', u'PERSON'), (u'Lagarde', u'PERSON'), (u'discussed', u'O'), (u'short-term', u'O'), (u'stimulus', u'O'), (u'efforts', u'O'), (u'in', u'O'), (u'a', u'O'), (u'recent', u'O'), (u'interview', u'O'), (u'with', u'O'), (u'the', u'O'), (u'Wall', u'ORGANIZATION'), (u'Street', u'ORGANIZATION'), (u'Journal', u'ORGANIZATION'), (u'.', u'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('stanford-ner/classifiers/english.conll.4class.distsim.crf.ser.gz',\n",
    "   'stanford-ner/stanford-ner-3.8.0.jar',\n",
    "   encoding='utf-8')\n",
    "\n",
    "text = 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.'\n",
    "\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "headers = ['Type','Prediction']\n",
    "rows = []\n",
    "PER = ''\n",
    "LOC = ''\n",
    "ORG = ''\n",
    "MISC = ''\n",
    "\n",
    "txt = 'test.txt'\n",
    "with open(txt, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "for i in range(0,len(data),3):\n",
    "        word_line = data[i].split()\n",
    "        num_line = data[i+2].split()\n",
    "    \n",
    "        tags = st.tag(word_line)\n",
    "        tags = stanfordNE2BIO(tags)\n",
    "        tagging2(tags,num_line)\n",
    "        \n",
    "\n",
    "\n",
    "rows.append(('PER',PER))\n",
    "rows.append(('LOC',LOC))\n",
    "rows.append(('ORG',ORG))\n",
    "rows.append(('MISC',MISC))\n",
    "               \n",
    "            \n",
    "with open('CRF_2.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
