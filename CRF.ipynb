{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "txt = 'train.txt'\n",
    "with open(txt, 'r') as file:\n",
    "    data = file.readlines()\n",
    "validation_len = len(data)/5\n",
    "validation_set = data[0:validation_len]\n",
    "train_set = data[validation_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract features from words. \n",
    "def word2features(word_line,pos_line,i):\n",
    "    word = word_line[i]\n",
    "    postag = pos_line[i]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = word_line[i-1]\n",
    "        postag1 = pos_line[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(word_line)-1:\n",
    "        word1 = word_line[i+1]\n",
    "        postag1 = pos_line[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# contruct train and test set for trainer\n",
    "def data2features(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(0,len(data),3):\n",
    "        word_line = data[i].split()\n",
    "        pos_line = data[i+1].split()\n",
    "        NE_line = data[i+2].split()\n",
    "\n",
    "        feature = [word2features(word_line,pos_line,i) for i in range(len(word_line))]\n",
    "        label = NE_line\n",
    "\n",
    "        X.append(feature)\n",
    "        Y.append(label)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,y_train = data2features(train_set)\n",
    "X_test,y_test = data2features(validation_set)\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 79.9 ms, total: 12.5 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "trainer.train('NER')\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('NER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 318 ms, sys: 28.7 ms, total: 347 ms\n",
      "Wall time: 348 ms\n"
     ]
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to output the NE results\n",
    "def tagging(begin_index,end_index,tag):\n",
    "    global PER,LOC,ORG,MISC\n",
    "    if tag == 'PER':\n",
    "         PER =  PER+str(begin_index)+'-'+str(end_index)+' '\n",
    "    if tag == 'LOC':\n",
    "        LOC =  LOC+str(begin_index)+'-'+str(end_index)+' '\n",
    "    if tag == 'ORG':\n",
    "        ORG =  ORG+str(begin_index)+'-'+str(end_index)+' '\n",
    "    if tag == 'MISC':\n",
    "        MISC = MISC+str(begin_index)+'-'+str(end_index)+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function2 to output the NE results\n",
    "def tagging2(tags,num_line):\n",
    "    begin = False\n",
    "    for i in range(len(tags)):\n",
    "        if tags[i][0]=='B':\n",
    "            begin_index = num_line[i]\n",
    "            if begin == True:\n",
    "                tag = tags[i-1][2:]\n",
    "                end_index = num_line[i-1]\n",
    "                tagging(begin_index,end_index,tag)\n",
    "            begin = True\n",
    "            \n",
    "        if tags[i][0]=='O' and begin==True:\n",
    "                tag = tags[i-1][2:]\n",
    "                end_index = num_line[i-1]\n",
    "                tagging(begin_index,end_index,tag)\n",
    "                begin = False\n",
    "                \n",
    "        if i == len(tags) and begin==True:\n",
    "            tag = tags[i][2:]\n",
    "            end_index = num_line[i]\n",
    "            tagging(begin_index,end_index,tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x11666cfd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'train.txt'\n",
    "with open(txt, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "X_train,y_train = data2features(data)\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "    \n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "trainer.train('NER')\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('NER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['Type','Prediction']\n",
    "rows = []\n",
    "PER = ''\n",
    "LOC = ''\n",
    "ORG = ''\n",
    "MISC = ''\n",
    "\n",
    "txt = 'test.txt'\n",
    "with open(txt, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "for i in range(0,len(data),3):\n",
    "        word_line = data[i].split()\n",
    "        pos_line = data[i+1].split()\n",
    "        num_line = data[i+2].split()\n",
    "    \n",
    "        feature = [word2features(word_line,pos_line,i) for i in range(len(word_line))]\n",
    "        tags = tagger.tag(feature)\n",
    "        tagging2(tags,num_line)\n",
    "        \n",
    "\n",
    "\n",
    "rows.append(('PER',PER))\n",
    "rows.append(('LOC',LOC))\n",
    "rows.append(('ORG',ORG))\n",
    "rows.append(('MISC',MISC))\n",
    "               \n",
    "            \n",
    "with open('CRF.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
